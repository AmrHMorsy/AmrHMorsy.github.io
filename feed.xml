<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://amrhmorsy.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://amrhmorsy.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-08T11:20:18+00:00</updated><id>https://amrhmorsy.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">How I Built a Vulkan Rendering Engine</title><link href="https://amrhmorsy.github.io/blog/2025/HowIBuiltaVulkanRenderingEngine/" rel="alternate" type="text/html" title="How I Built a Vulkan Rendering Engine"/><published>2025-09-04T12:00:00+00:00</published><updated>2025-09-04T12:00:00+00:00</updated><id>https://amrhmorsy.github.io/blog/2025/HowIBuiltaVulkanRenderingEngine</id><content type="html" xml:base="https://amrhmorsy.github.io/blog/2025/HowIBuiltaVulkanRenderingEngine/"><![CDATA[<p><br/></p> <h3 id="introduction-"><strong>Introduction</strong> <br/></h3> <p><br/></p> <p>In this blog post, I am going to share my entire development journey in building a rendering engine using the <a href="https://www.vulkan.org">Vulkan</a> API. The engine features Physically-Based Rendering (PBR), HDR skybox, Image-Based Lighting (IBL), frustum culling, shadow mapping and depth pre-pass. I named the engine <strong>Vejaler</strong> and published its source code <a href="https://vejaler.github.io">here</a>.</p> <p>Although the engine is still under development, I thought it might be worthwhile to document what I have built so far, and share the challenges I have faced early-on.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/CarOnBridgeScene-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/CarOnBridgeScene-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/CarOnBridgeScene-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/CarOnBridgeScene.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">A scene of a car on a bridge in the morning, rendered using Vejaler.</figcaption> </figure> </div> </div> <p><br/></p> <p><br/></p> <h3 id="why-i-wanted-to-learn-vulkan-"><strong>Why I Wanted To Learn Vulkan</strong> <br/></h3> <p><br/></p> <p>I started my graphics programming journey in January 2022, after finishing my computer graphics course at Concordia University, in Montreal, Canada. During the course, I got introduced to OpenGL and built a simple simulation as part of the required project. However, I fell in love with graphics programming as a career then, and decided to pursue it full-time while completing my degree.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/ClothSimulation-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/ClothSimulation-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/ClothSimulation-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/ClothSimulation.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">Cloth simulation, built using my OpenGL engine</figcaption> </figure> </div> </div> <p><br/></p> <p>After finishing the course, I started diving deeper into more advanced computer graphics topics, such as PBR, IBL, portal culling, occlusion culling, etc…, and was using OpenGL as the main API to apply the concepts I learnt from the textbooks, and also build advanced applications such as ocean simulation, cloth simulation, procedural-terrain generation and more.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/OceanSimulation-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/OceanSimulation-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/OceanSimulation-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/OceanSimulation.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">Ocean simulation, built using my OpenGL engine</figcaption> </figure> </div> </div> <p><br/></p> <p>I quickly became proficient in OpenGL and was able to build a complete engine using it. However, in efforts to become an all-around better graphics programmer, I wanted to have more APIs in my arsenal, and understand the graphics pipeline at a deeper level. OpenGL, while simple and easy to use and learn, is an outdated and a high-level API, which abstracts a lot of details from the developer and restricts advanced and custom development. As a result, I decided to embark on the journey of learning and mastering Vulkan. Although Vulkan is verbose and difficult to learn and use, it is a low-level API, which provides the programmer so much control over the rendering pipeline.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/PianoRoomScene-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/PianoRoomScene-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/PianoRoomScene-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/PianoRoomScene.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">A scene of a piano room in a house, rendered using my OpenGL engine</figcaption> </figure> </div> </div> <p><br/></p> <h3 id="early-days-"><strong>Early Days</strong> <br/></h3> <p><br/></p> <p>I started my journey in January 2025 by first creating a small window with a simple triangle. This took me almost a week just to get right, because of the many vulkan entities that needs to be set and initialized. It takes so many lines of code to just create a simple window. At first, nothing made sense to me.</p> <p>What is a window surface ? <br/> What is the logical and the physical device ? <br/> What is image and image view ? <br/></p> <p>Although I was able to create a very simple triangle scene, I didn’t understand much about what was going on under the hood. This was not unusual to me. I have always faced difficulties with new advanced topics, and experience has taught not me to dwell on the lack of understanding, and instead continue progressing deeper into the topic. Grasping the topic is inevitable with time. This rule has never failed me, which is why I continued re-reading the Vulkan documentation, and adding more advanced features.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20TriangleScene-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20TriangleScene-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20TriangleScene-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20TriangleScene.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">A scene of a simple triangle</figcaption> </figure> </div> </div> <p><br/></p> <p>After rendering that simple triangle, I thought the next logical step would be to load an OBJ model. It’s the simplest extension at that point, since all I had to do was load the OBJ model using the <a href="">Assimp</a> library, upload the vertex data inside the vertex buffer and create an extra index buffer and upload the index data to it. With just a few extra steps, the engine was capable of rendering more complex 3D models, instead of just a simple polygon.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20ModelSceneNoDepthTesting-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20ModelSceneNoDepthTesting-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20ModelSceneNoDepthTesting-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20ModelSceneNoDepthTesting.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">A scene of a simple 3D model</figcaption> </figure> </div> </div> <p><br/></p> <p>Although the engine was capable of rendering 3D models, depth testing wasn’t implemented at that time, resulting in incorrect scenes. Unlike OpenGL where depth testing is implemented for you, in Vulkan, the developer has to create the depth image and image view, besides the color attachment, and attach it to the main frameBuffer, for depth values to be stored, and for depth testing to be activated.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20ModelScene-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20ModelScene-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20ModelScene-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/Simple%20ModelScene.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">A scene of a simple 3D model</figcaption> </figure> </div> </div> <p><br/></p> <p>The development journey, at that point of time, became much smoother. I started enjoying Vulkan, because I was able to experiment with the different configurations, and actually see it reflect directly on the screen.</p> <p>For example, I started adding a functionality that allows the camera to roam freely in the scene. This involved a series of steps, which included building a view and a projection matrix, creating a uniform buffer to upload these matrices into, and finally update the descriptor sets to account for the extra binding of the uniform data in the vertex shader. This allowed me to produce renders from different point of views, and create a reasonably good foundation for more advanced scenes.</p> <p><br/></p> <h3 id="refactoring-engine-code-"><strong>Refactoring Engine Code</strong> <br/></h3> <p><br/></p> <p>At that point, I decided to stop adding more features, and instead try to understand Vulkan in more details. I wanted to grasp the purpose of each vulkan construct, and recognize how they are connected in the graphics pipeline. In my experience, the way I understand any source code has always been through refactoring the code. That is, I started re-organizing the code into classes, where each class is a stateless utility-style unit which manages a single vulkan entity in the rendering pipeline.</p> <p>For example, I created a graphics pipeline class which is responsible for creating, binding and destroying a graphics pipeline object, as well as managing its configurations. I continued refactoring all Vulkan constructs in my program into static components and grouped them all into a single module called “Engine”. This way, whenever I need to create a vulkan object, I could simply call a single function in the engine module <br/> <strong>(Engine::GraphicsPipeline::BuildGraphicsPipeline(GraphicsPipelineBuildConfiguration{}))</strong> <br/> and provide it with all the needed parameters, to build that object and return it. This design choice reduced the clutter in the source files, and created a clean workflow that can easily be understood by anyone, including future me.</p> <p>Once I refactored the engine code, it became clear to me why Vulkan is a superior choice as a graphics API. Its verbosity and low-levelness can be a headache, yes. But once I was able to have a grasp of the entities involved in the rendering pipeline, I started prefering Vulkan over any other APIs I have worked with in the past. It gives me the ability to control every aspect in application, and, hence, the ability to hack and optimize some features, where no higher-level API would have allowed me to do so.</p> <p>I was excited to continue developing the engine further and add more features. That’s why, I decided that the next set of funtionalities to implement should be: Textures, a lighting system and physically-based rendering (PBR).</p> <p><br/></p> <h3 id="adding-support-for-textures-"><strong>Adding Support for Textures</strong> <br/></h3> <p><br/></p> <p>At that point, the engine was capable of rendering 3D models, but with solid colors only. The obvious next step of development was to add support for textures. Implementing textures was a bit tricky, as it involved several steps. The first step was obvious to me: I needed to load the image first. This part of the implementation was similar to how I used to do it in OpenGL. I used the library <a href="">STB_Image</a> to load the image data, and then store loaded data inside a vulkan buffer.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/MedievalHouseScene-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/MedievalHouseScene-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/MedievalHouseScene-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/MedievalHouseScene.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">A scene of a medieval house with a texture, rendered using Vejaler.</figcaption> </figure> </div> </div> <p><br/></p> <p>The next remaining set of steps involved creating a vulkan image, image view and a sampler. The image created then was an empty image construct, with no data stored inside it. That’s why, the subsequent step was to copy the image data from the vulkan buffer into the created vulkan image, while taking into consideration the necessary image layout transitions that needed to be done for the process to be successful. Finally, what was left after that was simply to update the descriptor sets by adding an additional descriptor image binding slot. With these implementations in place, I was able to see complex 3D models rendered with textures.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/TruckScene-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/TruckScene-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/TruckScene-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/TruckScene.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">A scene of a truck, rendered using Vejaler.</figcaption> </figure> </div> </div> <p><br/></p> <p><br/></p> <h3 id="implementing-a-lighting-system-"><strong>Implementing A Lighting System</strong> <br/></h3> <p><br/></p> <p>The scenes I had rendered so far were flat and unrealistic. Adding a lighting system was the simplest and most obvious functionality to be next included in the engine, as it would make the scenes more physically accurate and visually better. All I had to do was simply create a new uniform buffer in the fragment shader and fill it with information like the position and the intensity of the light source, and then update the descriptor set to account for the extra binding of that fragment shader uniform buffer.</p> <p>However, something was missing in this implementation. Only one light source was accepted, which is unpractical, as a scene can have multiple. Although this can easily be fixed by passing an array of light positions and intensities to the uniform buffer, one issue arised. The size of the array in the shader must be known at compile-time. It cannot be dynamically determined at run-time. This posed restrictiveness on the engine’s ability to handle any random scene. The best solution I could find at that time was to define a MAX_NUM_LIGHTS varible in the shader and initialize it with a high number, and ensure that the user-defined number of light sources in the scene doesn’t exceed that limit. This was a resonable solution, though I am unsure if it was the best and most effecient fix for the problem.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/GramophoneScene-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/GramophoneScene-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/GramophoneScene-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/GramophoneScene.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">A scene of a Gramophone, featuring PBR, rendered using Vejaler.</figcaption> </figure> </div> </div> <p><br/></p> <p>The development journey so far was relatively smooth. There were no major obstacles being faced that I wasn’t able to intuitively straightforwardly handle and resolve. Luckily, there were no new Vulkan constructs to learn about. I got introduced to the majority of them at the very beginning when I was creating the simple triangle, and I kept re-using and recreating them for different features.</p> <p><br/></p> <h3 id="implementing-pbr-"><strong>Implementing PBR</strong> <br/></h3> <p><br/></p> <p>Implementing PBR at that time was the most obvious next step of development. The engine supported textures as well as a lighting system. Extending the engine to support PBR only required that I update the number of textures being supported to account for all the images in the PBR pipeline: Albedo, Displacement, Roughness, Opacity, Ambient Occlusion, Normal and Metallic. As for the shader code, I have already implemented PBR before in my OpenGL engine. All I had to do was refactor that code into my Vulkan engine.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/ViolinScene-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/ViolinScene-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/ViolinScene-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/ViolinScene.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">A scene of a violin, featuring PBR, rendered using Vejaler</figcaption> </figure> </div> </div> <p><br/></p> <p>My rendering engine was able to produce reasonably accurate and realistic visuals. I experimented with many different scenes, using different number of light sources and intensities, in order to test the engine’s ability to handle all kinds of inputs. The issue that arised at that point was the lack of support for different image formats. My engine supported only png images, which was not practical nor effecient. Therefore, I added the support for all possible image formats, and account for the mismatch between the actual and the expected number of channels in the image.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/FireHydrantScene-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/FireHydrantScene-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/FireHydrantScene-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/FireHydrantScene.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">A scene of a Fire Hydrant, featuring PBR, rendered using Vejaler.</figcaption> </figure> </div> </div> <p><br/></p> <p>One thing I noticed in my PBR implementation was the fact that I was uploading textures like Metallic, AO, displacement and opacity, and only sampling from the red channel of the image. This was an inefficiency that could easily be resolved by merging several images in the PBR pipeline into one texture.</p> <p>I merged the albedo and the AO image into one texture, where the albedo occupied the RGB component and the AO value occupied the A component. In a similar fashion, I also merged the normal and the roughness images. As for the metallic, displacement and opacity values, I merged all of them into one texture. This optimized my shader greatly, as then PBR can only be implemented using 3 textures, instead of 7 seperate textures.</p> <p><br/></p> <div class="row mt-3 text-center"> <div class="col-sm"> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/AlbedoAO-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/AlbedoAO-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/AlbedoAO-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/AlbedoAO.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">AlbedoAO of Fire Hydrant</figcaption> </figure> </div> <div class="col-sm"> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/NormalRoughness-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/NormalRoughness-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/NormalRoughness-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/NormalRoughness.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">NormalRoughness of Fire Hydrant</figcaption> </figure> </div> <div class="col-sm"> <figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/MetallicDisplacementOpacity-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/MetallicDisplacementOpacity-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/MetallicDisplacementOpacity-1400.webp"/> <img src="/assets/img/Blog/HowIBuiltaVulkanRenderingEngine/MetallicDisplacementOpacity.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="mt-2 text-muted">MetallicDisplacementOpacity of Fire Hydrant</figcaption> </figure> </div> </div> <p><br/></p> <hr/> <p><br/> <br/></p> <p>To Be Continued ….</p>]]></content><author><name></name></author><category term="Vulkan"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Barycentric Coordinates</title><link href="https://amrhmorsy.github.io/blog/2025/BarycentricCoordinates/" rel="alternate" type="text/html" title="Barycentric Coordinates"/><published>2025-02-09T12:00:00+00:00</published><updated>2025-02-09T12:00:00+00:00</updated><id>https://amrhmorsy.github.io/blog/2025/BarycentricCoordinates</id><content type="html" xml:base="https://amrhmorsy.github.io/blog/2025/BarycentricCoordinates/"><![CDATA[<p><br/></p> <h3 id="introduction-"><strong>Introduction</strong> <br/></h3> <p><br/></p> <p>A <strong>nondegenerate</strong> triangle is a triangle where:</p> <ul> <li>All vertices are distinct</li> <li>The vertices do not all lie on a single line (Non-collinear vertices)</li> </ul> <p><br/></p> <p>Consider the following <strong>nondegenerate</strong> triangle with vertices \(A\), \(B\), and \(C\).</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/1-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>A point \(Q\) that lies on the edge \(AB\) has the form</p> \[Q = (1-t)A + tB\] <p>where \(0 \leq t \leq 1\).</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/2-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>Similarly, a point \(R\) that lies on the edge \(QC\) has the form</p> \[R = (1-s)Q + sC\] <p>where \(0 \leq s \leq 1\).</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/3-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>We can rewrite \(R\) by substituting the equation for \(Q\). This results in the following equation</p> \[R = (1-s)((1-t)A + tB) + sC\] \[R = (1-s)(1-t)A + (1-s)tB + sC\] <p>Now, if we sum the coefficients of equation of \(R\), we get</p> \[(1-s)(1-t) + (1-s)t + s = (1 - t - s + st) + (t - st) + s = 1\] <p>Since \(R\) is an arbitrary point inside the triangle \(ABC\), we can generalize the equation to any point \(P\).</p> <p>That is, any point \(P\) inside the triangle \(ABC\) has the form</p> \[P = αA + βB + γC\] <p>where \(α + β + γ = 1\) and \(α, β, γ \geq 0\).</p> <p>These coefficients \(α\), \(β\) and \(γ\) are called the <strong>barycentric coordinates</strong> of \(P\) with respect to the triangle \(ABC\), such that</p> <ul> <li>If \(α = 0\), then \(P\) lies on the edge \(BC\)</li> <li>If \(β = 0\), then \(P\) lies on the edge \(AC\)</li> <li>If \(γ = 0\), then \(P\) lies on the edge \(AB\).</li> </ul> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/4-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/4-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/4-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p><br/></p> <h3 id="calculating-barycentric-coordinates-"><strong>Calculating Barycentric Coordinates</strong> <br/></h3> <p><br/></p> <p>The equations for calculating the <strong>barycentric coordinates</strong> are</p> \[α = \frac{Area(▲PBC)}{Area(▲ABC)}\] \[β = \frac{Area(▲PAC)}{Area(▲ABC)}\] \[γ = \frac{Area(▲PAB)}{Area(▲ABC)}\] <p>The proof for these equations will be explained later in this blog post.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/5-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/5-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/5-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/5.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p><br/></p> <h3 id="calculating-area-of-the-triangle-"><strong>Calculating Area of the Triangle</strong> <br/></h3> <p><br/></p> <p>There are 2 ways to calculate the area of the triangle:</p> <p><strong>Approach 1</strong></p> <p>The area of the triangle is</p> \[Area = \frac{1}{2} \times Base \times Height\] <p>where \(Height\) is the perpendicular shortest distance from the the base edge to the opposite vertex.</p> <p>For example, the area of triangle \(PBC\) is</p> \[Area(▲PBC) = \frac{1}{2} \times ||\vec{BC}|| \times d_{⊥} (P,BC)\] <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/6-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/6-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/6-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/6.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p><strong>Approach 2</strong></p> <p>Another easier way to calculate the area of the triangle, is to use the area of the parallelogram.</p> <p>Consider the parallelogram \(ABCD\). The area of the parallelogram \(ABCD\) is</p> \[Area(▰ABCD) = ||\vec{AB}|| \times ||\vec{AC}|| \times sin(\theta)\] <p>We can also express the area of the parallelogram \(ABCD\) as the magnitude of the cross product of two vectors that lie on the parallelogram. That is,</p> \[Area(▰ABCD) = ||\vec{AB} \times \vec{AC}||\] <p>The area of the triangle is equal to half the area of the parallelogram. Hence, the area of the triangle \(ABC\) can be expressed as</p> \[Area(▲ABC) = \frac{||\vec{AB}|| \times ||\vec{AC}|| \times sin(\theta)}{2} = \frac{||\vec{AB} \times \vec{AC}|| }{2}\] <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/7-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/7.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p><br/></p> <h3 id="proof-"><strong>Proof</strong> <br/></h3> <p><br/></p> <p>Consider the triangle \(ABC\). Let \(P\) be a point inside the triangle. We know that</p> \[P = αA + βB + γC\] <p>where \(α + β + γ = 1\) and \(α, β, γ \geq 0\).</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/5-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/5-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/5-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/5.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>We want to prove that</p> \[α = \frac{Area(▲PBC)}{Area(▲ABC)}\] \[β = \frac{Area(▲PAC)}{Area(▲ABC)}\] \[γ = \frac{Area(▲PAB)}{Area(▲ABC)}\] <p>Without loss of generality, consider the barycentric coordinate \(α\).</p> <p>Let \(d_P\) be the perpendicular distance from \(P\) to \(BC\) and \(d_A\) be the perpendicular distance from \(A\) to \(BC\).</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/9-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/9-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/9-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/9.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>We know that the area of triangle \(PBC\) is</p> \[Area(▲PBC) = \frac{1}{2} \times ||\vec{BC}|| \times d_P\] <p>and the area of triangle \(ABC\) is</p> \[Area(▲ABC) = \frac{1}{2} \times ||\vec{BC}|| \times d_A\] <p>From these equations, we can see that</p> <ul> <li>\(Area(▲PBC)\) is linearly proportional to the perpendicular distance from \(P\) to \(BC\) ; \(d_P\)</li> </ul> \[Area(▲PBC) ∝ d_P\] <ul> <li>\(Area(▲ABC)\) is linearly proportional to the perpendicular distance from \(A\) to \(BC\) ; \(d_A\).</li> </ul> \[Area(▲ABC) ∝ d_A\] <p>As \(d_P\) decreases, the point \(P\) becomes closer to the edge \(BC\), causing the value of \(α\) to also decrease. When \(d_P=0\), the point \(P\) lies on the edge \(BC\) and \(α=0\).</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/10-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/10-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/10-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/10.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>As \(d_P\) increases, the point \(P\) becomes closer to the point \(A\), causing the value of \(α\) to increase. When \(d_P=d_A\), the point \(P\) coincides the point \(A\) and \(α=1\).</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/11-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/11.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>This implies that \(α\) is proportional to \(d_P\)</p> \[α ∝ d_P\] <p>where the proportionality constant is \(d_A\).</p> <p>That is,</p> \[α = \frac{d_P}{d_A}\] <p>Since \(d_P\) is linearly proportional to \(Area(PBC)\) and \(d_A\) is linearly proportional to \(Area(ABC)\), then we can rewrite \(α\) as</p> \[α = \frac{Area(▲PBC)}{Area(▲ABC)}\] <p>By applying the same reasoning to the other two coordinates, we obtain that</p> \[β = \frac{Area(▲PAC)}{Area(▲ABC)}\] \[γ = \frac{Area(▲PAB)}{Area(▲ABC)}\] <p>Thus, proof is complete.</p> <p><br/></p> <h3 id="applications-of-barycentric-coordinates-"><strong>Applications of Barycentric Coordinates</strong> <br/></h3> <p><br/></p> <p>In modern <strong>computer graphics</strong>, triangles are the fundamental building block for rendering.</p> <p>All complex geometric meshes are processed in the GPU (Graphics Processing Unit) in terms of triangles.</p> <p>Regardless of how complex a 3D model is (e.g., spheres, characters, buildings, etc..), it is ultimately broken down into a mesh of triangles that the GPU processes.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/12-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/12.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>Why triangles? Because today’s <strong>GPUs (Graphics Processing Units)</strong> are highly optimized to handle triangle-based operations very efficiently.</p> <p>Because triangles are such a widely used geometric primitive, there are many applications for <strong>barycentric coordinates</strong>.</p> <p>One of the key steps in the graphics pipeline is <strong>rasterization</strong>.</p> <p>During <strong>rasterization</strong>, the GPU needs to determine whether a pixel is inside the triangle or outside the triangle.</p> <p>If the pixel is inside the triangle, it will be shaded. If the pixel is outside the triangle, it will not be shaded.</p> <p>The GPU uses <strong>barycentric coordinates</strong> \(α\), \(β\), and \(γ\), given the pixel coordinates and the coordinates of each vertex of the triangle, to determine if the pixel is inside the triangle or outside the triangle.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Barycentric_Coordinates/13-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Barycentric_Coordinates/13-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Barycentric_Coordinates/13-1400.webp"/> <img src="/assets/img/Blog/Barycentric_Coordinates/13.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>If \(α + β + γ = 1\) and \(α, β, γ \geq 0\), then the pixel is inside the triangle and it will be shaded.</p> <p>Otherwise, the pixel is outside the triangle and it will not be shaded.</p> <hr/> <p><br/></p> <h3 id="references"><strong>References</strong></h3> <p><br/></p> <ul> <li>Chapter 7.9.1 - Computer Graphics: Principles and Practice by John F. Hughes</li> </ul> <p><br/></p> <hr/> <p><br/> <br/></p> <blockquote> <p><strong>Need help with computer graphics?</strong> <br/> <br/> I offer one-on-one tutoring for students and professionals, covering all levels of computer graphics along with the APIs <u>OpenGL</u>, <u>WebGL</u>, <u>Vulkan</u>, <u>Metal</u>, and <u>Direct3D</u> for developing game engines, simulations, animations, and video games. <br/> <br/> Learn more → <a href="https://amrhmorsy.github.io/tutoring/">Tutoring</a></p> </blockquote>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Refraction Vector Calculation</title><link href="https://amrhmorsy.github.io/blog/2024/RefractionVectorCalculation/" rel="alternate" type="text/html" title="Refraction Vector Calculation"/><published>2024-10-31T12:00:00+00:00</published><updated>2024-10-31T12:00:00+00:00</updated><id>https://amrhmorsy.github.io/blog/2024/RefractionVectorCalculation</id><content type="html" xml:base="https://amrhmorsy.github.io/blog/2024/RefractionVectorCalculation/"><![CDATA[<p><br/></p> <h3 id="introduction-"><strong>Introduction</strong> <br/></h3> <p><br/></p> <p>When a beam of light hits the surface of an object, part of its energy is absorbed by the surface, part of its energy is reflected away and part of its energy may refract through the object itself.</p> <p>In this post, we will explore the mathematics behind calculating the refraction vector.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/1-1400.webp"/> <img src="/assets/img/Blog/Refraction_Vector_Calculation/1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p><br/></p> <h3 id="snell-law-"><strong>Snell Law</strong> <br/></h3> <p><br/></p> <p>Transparent surfaces have a property called the <strong>index of refraction</strong>. This refractive index determines how much the path of light is bent or refracted, when entering a material. This can be explained by <strong>Snell’s Law</strong>.</p> <p>Let:</p> <ul> <li>\(n_L\) be the index of refraction of the material the light is leaving,</li> <li>\(\theta_L\) be the angle of incidence,</li> <li>\(n_T\) be the index of refraction of the material the light is entering, and</li> <li>\(\theta_T\) be the angle of refraction.</li> </ul> <p>According to Snell’s Law,</p> \[n_L sin \theta_L = n_T sin \theta_T\] <p>Each material has its own unique index of refraction. For example, the index of refraction of air is <strong>1.000293</strong>, while the index of refraction of diamond is <strong>2.417</strong>. Higher indexes of refraction create a greater bending effect at the interface between two materials, causing the refraction vector to bend more towards the normal vector.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/2-1400.webp"/> <img src="/assets/img/Blog/Refraction_Vector_Calculation/2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>Now, let:</p> <ul> <li>\(L\) be the incoming light vector,</li> <li>\(N\) be the normal vector, and</li> <li>\(T\) be the refracted light vector.</li> </ul> <p>We assume that \(L\), \(N\) and \(T\) are normalized to unit length.</p> <p><br/></p> <h3 id="decomposition-of-incoming-light-vector-l-">Decomposition of Incoming Light Vector \(L\) <br/></h3> <p><br/></p> <p>To calculate the refraction vector \(T\), we first need to decompose the incoming light vector \(L\) in relation to the surface normal vector \(N\).</p> <p>Each vector has both a parallel component and perpendicular component relative to the normal vector \(N\).</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/3-1400.webp"/> <img src="/assets/img/Blog/Refraction_Vector_Calculation/3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>The parallel component of \(L\) along \(N\) is</p> \[L_{||N} = (N.L)N = N cos \theta_L\] <p>The perpendicular component of \(L\) along \(N\) can be calculated by subtracting \(L_{||N}\) from \(L\) . That is,</p> \[L_{⊥N} = L - L_{||N} = L - (N.L)N\] <p>Next, let’s calculate the magnitudes of \(L_{||N}\) and \(L_{⊥N}\)</p> <p>Since the vectors \(L\) , \(L_{||N}\) and \(L_{⊥N}\) form a right-angled triangle, we can use trignometric relationships to calculate their magnitudes.</p> <p>We know that</p> \[sin\theta_L = \frac{|L_{⊥N}|}{L}\] <p>and</p> \[cos\theta_L = \frac{|L_{||N}|}{L}\] <p>Since \(L\) has been normalized to unit length (i.e., \(|L| = 1\) ), then</p> \[|L_{⊥N}| = sin \theta_L\] <p>and</p> \[|L_{||N}| = cos \theta_L\] <p><br/></p> <h3 id="decomposition-of-refraction-vector-t-"><strong>Decomposition of Refraction Vector \(T\)</strong> <br/></h3> <p><br/></p> <p>Just like we did with the incoming light vector \(L\), we are going to decompose the refraction vector \(T\) in relation to the surface normal vector \(N\).</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/4-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/4-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Refraction_Vector_Calculation/4-1400.webp"/> <img src="/assets/img/Blog/Refraction_Vector_Calculation/4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>The parallel component of \(T\) along \(N\) is</p> \[T_{||N} = (-N.T)(-N) = -N cos \theta_T\] <p>As we know, we can calculate the perpendicular component of \(T\) along \(N\) as:</p> \[T_{⊥N} = T - T_{||}\] <p>However, we do not know \(T\). Hence, we must find another way to calculate \(T_{⊥N}\).</p> <p>Let’s first calculate the magnitudes of \(T_{||N}\) and \(T_{⊥N}\) .</p> <p>Since the vectors \(T\) , \(T_{||N}\) and \(T_{⊥N}\) form a right-angled triangle, we can use trignometric relationships to calculate their magnitudes.</p> <p>We know that</p> \[sin\theta_T = \frac{|T_{⊥N}|}{|T|}\] <p>and</p> \[cos\theta_T = \frac{|T_{||}|}{T}\] <p>Since \(T\) is normalized to unit length(i.e., \(|T| = 1\) . Then,</p> \[|T_{⊥N}| = sin\theta_T\] <p>Now that we have \(|T_{⊥N}|\) , let’s return to the problem of calculating \(T_{⊥N}\) .</p> <p>Since \(T_{⊥N}\) has the same direction as \(L_{⊥N}\), then we can calculate \(T_⊥\) as:</p> \[T_⊥ = \frac{L_{⊥N}}{|L_{⊥N}|} |T_{⊥N}| = \frac{L_{⊥N}}{|L_{⊥N}|} sin \theta_T = \frac{L-(N.L)N}{sin \theta_L} sin \theta_T\] <p><br/></p> <h3 id="calculation-of-refraction-vector-t-"><strong>Calculation of Refraction Vector \(T\)</strong> <br/></h3> <p><br/></p> <p>Finally, we can calculate the refraction vector \(T\) by adding \(T_{||N}\) and \(T_{⊥N}\) . That is,</p> \[T = T_{||N} + T_{⊥N}\] \[T = (-N.T)(-N) + \frac{L-(N.L)N}{sin \theta_L} sin \theta_T\] \[T = -N cos \theta_T + \frac{L-(N.L)N}{sin \theta_L} sin \theta_T\] <p>Let’s do some further simplification to the equation.</p> <p>We can use <strong>Snell Law</strong> to replace \(\frac{sin\theta_T}{sin\theta_L}\) with \(\frac{n_L}{n_T}\). This yields:</p> \[T = -N cos \theta_T + \frac{n_L}{n_T}(L-(N.L)N)\] <p>We can also replace \(cos \theta_T\) with \(\sqrt{1-sin^2 \theta_T}\) , which gives us</p> \[T = -N \sqrt{1-sin^2 \theta_T} + \frac{n_L}{n_T}(L-(N.L)N)\] <p>Furthermore, we can use <strong>Snell Law</strong> to replace \(sin^2 \theta_T\) with \(\frac{n_L^2}{n_T^2} sin^2 \theta_L\) . The result is</p> \[T = -N \sqrt{1-\frac{n_L^2}{n_T^2} sin^2 \theta_L} + \frac{n_L}{n_T}(L-(N.L)N)\] <p>Finally, we can replace \(sin^2 \theta_L\) with \(1-cos^2 \theta_L = 1 - (N.L)^2\)</p> <p>This gives us:</p> \[T = -N \sqrt{1-\frac{n_L^2}{n_T^2} (1-(N.L)^2)} + \frac{n_L}{n_T}(L-(N.L)N)\] \[T = -N \sqrt{1-\frac{n_L^2}{n_T^2} (1-(N.L)^2)} + \frac{n_L}{n_T}L - \frac{n_L}{n_T}(N.L)N\] <p>\begin{equation} T = N ( - \frac{n_L}{n_T}(N.L) - \sqrt{1-\frac{n_L^2}{n_T^2} (1-(N.L)^2)} ) + \frac{n_L}{n_T}L \end{equation}</p> <p>Now, if you noticed, equation 1 contains a radical. If the quantity inside the radical is negative, the equation becomes invalid.</p> <p>To be more specific, equation 1 can become invalid if \(n_L &gt; n_T\) . This phenomena is called <strong>Total Internal Reflection</strong>, which means that no refraction is happening and the vector is reflecting off the surface. In this case, the equation for calculating the reflection vector is the one used.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/2-1400.webp"/> <img src="/assets/img/Blog/Reflection_Vector_Calculation/2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>Expressed another way, we can say that equation 1 is only valid when</p> \[sin \theta_L \leq \frac{n_T}{n_L}\] <p>Why ?</p> <p>Well, let’s prove it.</p> <p><br/></p> <h4 id="proof"><strong>Proof</strong></h4> <p><br/></p> <p>From equation 1, we can deduce that the equation becomes invalid when the quantity inside the radical becomes negative.</p> <p>Hence, equation 1 is valid only when</p> \[1-\frac{n_L^2}{n_T^2} (1-(N.L)^2) \geq 0\] <p>Rearranging the equation gives us:</p> \[\frac{n_L^2}{n_T^2} (1-(N.L)^2) \leq 1\] <p>We can divide both sides by \(\frac{n_L^2}{n_T^2}\) . This yields:</p> \[1-(N.L)^2 \leq \frac{n_T^2}{n_L^2}\] <p>Multiplying by -1 gives us:</p> \[(N.L)^2 -1 \geq - \frac{n_T^2}{n_L^2}\] \[(N.L)^2 \geq 1 - \frac{n_T^2}{n_L^2}\] <p>Now, since \(N.L = cos \theta_L\) , then</p> \[cos^2 \theta_L \geq 1 - \frac{n_T^2}{n_L^2}\] <p>We know that \(cos^2 \theta_L = 1 - sin^2 \theta_L\) . Hence,</p> \[1 - sin^2 \theta_L \geq 1 - \frac{n_T^2}{n_L^2}\] <p>Finally, rearranging the equation, multiplying by -1 and taking the square root in both sides gives us:</p> \[sin^2 \theta_L \leq \frac{n_T^2}{n_L^2}\] \[sin \theta_L \leq \frac{n_T}{n_L}\] <p>This completes the proof that equation 1 is only valid when</p> \[sin \theta_L \leq \frac{n_T}{n_L}\] <hr/> <p><br/></p> <h3 id="references">References</h3> <p><br/></p> <ul> <li>Chapter 6.4.2 - Mathematics for 3D Programming and Computer Graphics by Eric Lengyel</li> </ul> <p><br/></p> <hr/> <p><br/> <br/></p> <blockquote> <p><strong>Need help with computer graphics?</strong> <br/> <br/> I offer one-on-one tutoring for students and professionals, covering all levels of computer graphics along with the APIs <u>OpenGL</u>, <u>WebGL</u>, <u>Vulkan</u>, <u>Metal</u>, and <u>Direct3D</u> for developing game engines, simulations, animations, and video games. <br/> <br/> Learn more → <a href="https://amrhmorsy.github.io/tutoring/">Tutoring</a></p> </blockquote>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Reflection Vector Calculation</title><link href="https://amrhmorsy.github.io/blog/2024/ReflectionVectorCalculation/" rel="alternate" type="text/html" title="Reflection Vector Calculation"/><published>2024-10-28T12:00:00+00:00</published><updated>2024-10-28T12:00:00+00:00</updated><id>https://amrhmorsy.github.io/blog/2024/ReflectionVectorCalculation</id><content type="html" xml:base="https://amrhmorsy.github.io/blog/2024/ReflectionVectorCalculation/"><![CDATA[<p><br/></p> <h3 id="introduction-"><strong>Introduction</strong> <br/></h3> <p><br/></p> <p>When a beam of light hits the surface of an object, part of its energy is absorbed by the surface, part of its energy is reflected away and part of its energy may refract through the object itself.</p> <p>In this post, we will explore the mathematics behind calculating the reflection vector.</p> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/1-1400.webp"/> <img src="/assets/img/Blog/Reflection_Vector_Calculation/1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>Let:</p> <ul> <li>\(L\) be the incoming light vector</li> <li>\(N\) be the normal of the surface,</li> <li>\(R\) be the reflection vector of \(L\),</li> <li>\(\theta_i\) be the angle of incidence, and</li> <li>\(\theta_r\) be the angle of reflection, and</li> </ul> <p>We assume \(N\), \(L\) and \(R\) are normalized to unit length.</p> <p><br/></p> <h3 id="law-of-reflection-"><strong>Law of Reflection</strong> <br/></h3> <p><br/></p> <p>The law of reflection states that the angle of incidence is equal to the angle of reflection. That is,</p> \[\theta_i = \theta_r\] <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/2-1400.webp"/> <img src="/assets/img/Blog/Reflection_Vector_Calculation/2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p><br/></p> <h3 id="decomposition-of-vector-l-"><strong>Decomposition of Vector \(L\)</strong> <br/></h3> <p><br/></p> <p>To calculate the reflection vector \(R\), we first need to decompose the incoming light vector \(L\) in relation to the surface normal vector \(N\).</p> <p>The vector \(L\) has both a parallel component relative to \(N\) ; \(L_{||N}\) and a perpendicular component relative to \(N\) ; \(L_{⊥N}\) , such that</p> \[L = L_{||N} + L_{⊥N}\] <p>The parallel component of \(L\) along \(N\) is:</p> \[L_{||N} = (L.N)N = N cos \theta\] <p>The perpendicular component of \(L\) along \(N\) can be calculated by subtracting \(L_{||N}\) from \(L\) . That is,</p> \[L_{⊥N} = L - L_{||N} = L - (L.N)N\] <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/3-1400.webp"/> <img src="/assets/img/Blog/Reflection_Vector_Calculation/3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p>Just like we did with the incoming light vector \(L\), we are going to decompose the reflection vector \(R\) in relation to the surface normal vector \(N\).</p> <p>The vector \(R\) has both a parallel component relative to \(N\) ; \(R_{||N}\) and a perpendicular component relative to \(N\) ; \(R_{⊥N}\) , such that</p> \[R = R_{||N} + R_{⊥N}\] <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/4-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/4-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Blog/Reflection_Vector_Calculation/4-1400.webp"/> <img src="/assets/img/Blog/Reflection_Vector_Calculation/4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <p><br/></p> <h3 id="calculating-the-reflection-vector-r-"><strong>Calculating the Reflection Vector \(R\)</strong> <br/></h3> <p><br/></p> <p>Now, let’s calculate the reflection vector \(R\). Since</p> \[R = R_{||N} + R_{⊥N}\] <p>then we can calculate \(R\) by calculating its components \(R_{||N}\) and \(R_{⊥N}\) .</p> <p>By the law of reflection, the angle of incidence is equal to the angle of reflection; i.e \(\theta_i = \theta_r\)</p> <p>This means that the components of \(R\) is equal in magnitude to the components of \(L\), but they may have opposite directions.</p> <p>The perpendicular component of \(R\) along \(N\) ; \(R_{⊥N}\) has the same direction as the perpendicular component of \(L\) along \(N\) ; \(L_{⊥N}\) .</p> <p>The parallel component of \(R\) along \(N\) ; \(R_{||N}\) , is in the opposite direction of the parallel component of \(L\) along \(N\) ; \(L_{||N}\) .</p> <p>Hence, the reflection vector \(R\) can be calculated as follows:</p> \[R = L_⊥ - L_{||}\] \[R = L - (L.N)N - (L.N)N\] \[R = L - 2 (L.N)N\] <p><br/></p> <h3 id="implementation-">Implementation <br/></h3> <p><br/></p> <p>The GLM library has a built-in function that computes the reflection vector, given the normal and incident vector. Here’s the C++ code using the GLM library:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;glm/glm.hpp&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;glm/gtx/reflect.hpp&gt;</span><span class="cp">
</span>
<span class="n">glm</span><span class="o">::</span><span class="n">vec3</span> <span class="nf">compute_reflection_vector</span><span class="p">(</span> <span class="n">glm</span><span class="o">::</span><span class="n">vec3</span> <span class="n">L</span><span class="p">,</span> <span class="n">glm</span><span class="o">::</span><span class="n">vec3</span> <span class="n">N</span> <span class="p">)</span>
<span class="p">{</span>
    <span class="k">return</span> <span class="n">glm</span><span class="o">::</span><span class="n">reflect</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span> <span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <hr/> <p><br/></p> <h3 id="references">References</h3> <p><br/></p> <ul> <li>Chapter 6.4.1 - Mathematics for 3D Programming and Computer Graphics by Eric Lengyel</li> </ul> <p><br/></p> <hr/> <p><br/> <br/></p> <blockquote> <p><strong>Need help with computer graphics?</strong> <br/> <br/> I offer one-on-one tutoring for students and professionals, covering all levels of computer graphics along with the APIs <u>OpenGL</u>, <u>WebGL</u>, <u>Vulkan</u>, <u>Metal</u>, and <u>Direct3D</u> for developing game engines, simulations, animations, and video games. <br/> <br/> Learn more → <a href="https://amrhmorsy.github.io/tutoring/">Tutoring</a></p> </blockquote>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction]]></summary></entry></feed>